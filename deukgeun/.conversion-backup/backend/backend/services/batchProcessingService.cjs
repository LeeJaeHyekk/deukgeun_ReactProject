const { logger  } = require('../utils/logger');
const { ErrorHandlingService  } = require('./errorHandlingService');
class BatchProcessingService
module.exports.BatchProcessingService = BatchProcessingService {
    /**
     * ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ í—¬ìŠ¤ì¥ ë°ì´í„° ì—…ë°ì´íŠ¸
     */
    static async processGymsInBatches(gymRepo, updateFunction, config = {}) {
        const finalConfig = { ...this.DEFAULT_CONFIG, ...config };
        const allGyms = await gymRepo.find();
        logger.info(`ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: ${allGyms.length}ê°œ í—¬ìŠ¤ì¥, ë°°ì¹˜ í¬ê¸°: ${finalConfig.batchSize}`);
        const progress = {
            total: allGyms.length,
            processed: 0,
            success: 0,
            failed: 0,
            currentBatch: 0,
            totalBatches: Math.ceil(allGyms.length / finalConfig.batchSize),
            estimatedTimeRemaining: 0,
            startTime: new Date(),
            lastUpdateTime: new Date()
        };
        const results = [];
        const errors = [];
        // ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        const batches = this.createBatches(allGyms, finalConfig.batchSize);
        for (let i = 0; i < batches.length; i++) {
            progress.currentBatch = i + 1;
            const batch = batches[i];
            logger.info(`ğŸ“¦ ë°°ì¹˜ ${i + 1}/${batches.length} ì²˜ë¦¬ ì¤‘: ${batch.length}ê°œ í—¬ìŠ¤ì¥`);
            try {
                // ë°°ì¹˜ ë‚´ì—ì„œ ë™ì‹œ ì²˜ë¦¬
                const batchResults = await this.processBatchConcurrently(batch, updateFunction, finalConfig, progress);
                results.push(...batchResults.successful);
                errors.push(...batchResults.errors);
                progress.success += batchResults.successful.length;
                progress.failed += batchResults.errors.length;
                progress.processed += batch.length;
                // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                this.updateProgress(progress);
                // ë°°ì¹˜ ê°„ ì§€ì—°
                if (i < batches.length - 1) {
                    await new Promise(resolve => setTimeout(resolve, finalConfig.delayBetweenBatches));
                }
            }
            catch (error) {
                logger.error(`âŒ ë°°ì¹˜ ${i + 1} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
                errors.push(error);
                progress.failed += batch.length;
                progress.processed += batch.length;
            }
        }
        const duration = Date.now() - progress.startTime.getTime();
        logger.info(`âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ${progress.success}ê°œ ì„±ê³µ, ${progress.failed}ê°œ ì‹¤íŒ¨, ${duration}ms ì†Œìš”`);
        return {
            success: progress.failed === 0,
            data: results,
            errors,
            progress,
            duration
        };
    }
    /**
     * ë°°ì¹˜ë¥¼ ë™ì‹œì— ì²˜ë¦¬
     */
    static async processBatchConcurrently(batch, processFunction, config, progress) {
        const successful = [];
        const errors = [];
        // ë™ì‹œ ì²˜ë¦¬ ì œí•œ
        const semaphore = new Semaphore(config.concurrency);
        const promises = batch.map(async (item) => {
            await semaphore.acquire();
            try {
                const result = await this.processWithRetry(item, processFunction, config);
                successful.push(result);
                return result;
            }
            catch (error) {
                errors.push(error);
                throw error;
            }
            finally {
                semaphore.release();
            }
        });
        await Promise.allSettled(promises);
        return { successful, errors };
    }
    /**
     * ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ê°œë³„ ì²˜ë¦¬
     */
    static async processWithRetry(item, processFunction, config) {
        const context = {
            gymName: item.name || "unknown",
            source: "batch_processing",
            error: new Error("Initial error"),
            timestamp: new Date(),
            retryCount: 0
        };
        return ErrorHandlingService.retryWithBackoff(async () => {
            const timeoutPromise = new Promise((_, reject) => {
                setTimeout(() => reject(new Error("Timeout")), config.timeout);
            });
            const processPromise = processFunction(item);
            return Promise.race([processPromise, timeoutPromise]);
        }, context, config.maxRetries);
    }
    /**
     * ë°°ì—´ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
     */
    static createBatches(array, batchSize) {
        const batches = [];
        for (let i = 0; i < array.length; i += batchSize) {
            batches.push(array.slice(i, i + batchSize));
        }
        return batches;
    }
    /**
     * ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
     */
    static updateProgress(progress) {
        const now = new Date();
        const elapsed = now.getTime() - progress.startTime.getTime();
        if (progress.processed > 0) {
            const avgTimePerItem = elapsed / progress.processed;
            const remainingItems = progress.total - progress.processed;
            progress.estimatedTimeRemaining = avgTimePerItem * remainingItems;
        }
        progress.lastUpdateTime = now;
        // ì§„í–‰ë¥  ë¡œê¹…
        const percentage = ((progress.processed / progress.total) * 100).toFixed(1);
        logger.info(`ğŸ“Š ì§„í–‰ë¥ : ${percentage}% (${progress.processed}/${progress.total}) - ì„±ê³µ: ${progress.success}, ì‹¤íŒ¨: ${progress.failed}`);
    }
    /**
     * ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬
     */
    static async processWithMemoryOptimization(items, processFunction, config = {}) {
        const finalConfig = { ...this.DEFAULT_CONFIG, ...config };
        // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        const startMemory = process.memoryUsage();
        logger.info(`ğŸ’¾ ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ${this.formatBytes(startMemory.heapUsed)}`);
        const results = [];
        const errors = [];
        let processed = 0;
        // ìŠ¤íŠ¸ë¦¼ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
        for (let i = 0; i < items.length; i += finalConfig.batchSize) {
            const batch = items.slice(i, i + finalConfig.batchSize);
            try {
                const batchResults = await this.processBatchConcurrently(batch, processFunction, finalConfig, {
                    total: items.length,
                    processed,
                    success: results.length,
                    failed: errors.length,
                    currentBatch: Math.floor(i / finalConfig.batchSize) + 1,
                    totalBatches: Math.ceil(items.length / finalConfig.batchSize),
                    estimatedTimeRemaining: 0,
                    startTime: new Date(),
                    lastUpdateTime: new Date()
                });
                results.push(...batchResults.successful);
                errors.push(...batchResults.errors);
                processed += batch.length;
                // ë©”ëª¨ë¦¬ ì •ë¦¬
                if (global.gc) {
                    global.gc();
                }
                // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…
                const currentMemory = process.memoryUsage();
                logger.info(`ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ${this.formatBytes(currentMemory.heapUsed)}`);
            }
            catch (error) {
                logger.error(`âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
                errors.push(error);
                processed += batch.length;
            }
        }
        const endMemory = process.memoryUsage();
        logger.info(`ğŸ’¾ ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ${this.formatBytes(endMemory.heapUsed)}`);
        return {
            success: errors.length === 0,
            data: results,
            errors,
            progress: {
                total: items.length,
                processed,
                success: results.length,
                failed: errors.length,
                currentBatch: Math.ceil(items.length / finalConfig.batchSize),
                totalBatches: Math.ceil(items.length / finalConfig.batchSize),
                estimatedTimeRemaining: 0,
                startTime: new Date(),
                lastUpdateTime: new Date()
            },
            duration: 0
        };
    }
    /**
     * ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •
     */
    static calculateOptimalBatchSize(totalItems, availableMemory) {
        // ë©”ëª¨ë¦¬ ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        const estimatedMemoryPerItem = 1024 * 1024; // 1MB per item (ì¶”ì •)
        const maxItemsByMemory = Math.floor(availableMemory / estimatedMemoryPerItem);
        // ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°ì™€ ë©”ëª¨ë¦¬ ì œí•œ ì¤‘ ì‘ì€ ê°’ ì„ íƒ
        const optimalSize = Math.min(this.DEFAULT_CONFIG.batchSize, maxItemsByMemory);
        // ìµœì†Œê°’ ë³´ì¥
        return Math.max(optimalSize, 1);
    }
    /**
     * ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
     */
    static formatBytes(bytes) {
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        if (bytes === 0)
            return '0 Bytes';
        const i = Math.floor(Math.log(bytes) / Math.log(1024));
        return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
    }
}
BatchProcessingService.DEFAULT_CONFIG = {
    batchSize: 10,
    concurrency: 3,
    delayBetweenBatches: 1000,
    maxRetries: 3,
    timeout: 30000
};
/**
 * ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´ í´ë˜ìŠ¤
 */
class Semaphore {
    constructor(permits) {
        this.waiting = [];
        this.permits = permits;
    }
    async acquire() {
        if (this.permits > 0) {
            this.permits--;
            return Promise.resolve();
        }
        return new Promise((resolve) => {
            this.waiting.push(resolve);
        });
    }
    release() {
        if (this.waiting.length > 0) {
            const resolve = this.waiting.shift();
            resolve();
        }
        else {
            this.permits++;
        }
    }
}
