/**
 * í†µí•© í¬ë¡¤ë§ ì„œë¹„ìŠ¤
 * ëª¨ë“  í¬ë¡¤ë§ ê¸°ëŠ¥ì„ í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ë¡œ í†µí•©
 */

import { Repository } from 'typeorm'
import { Gym } from '../../../entities/Gym'
import { DataProcessor } from './DataProcessor'
import { PublicApiSource } from '@backend/modules/crawling/sources/PublicApiSource'
import { OptimizedGymCrawlingSource } from '@backend/modules/crawling/sources/OptimizedGymCrawlingSource'
import { DataMerger } from '@backend/modules/crawling/processors/DataMerger'
import { EnhancedDataMerger } from '@backend/modules/crawling/processors/EnhancedDataMerger'
import { DataValidator } from '@backend/modules/crawling/processors/DataValidator'
import { CrawlingHistoryTracker } from '@backend/modules/crawling/tracking/CrawlingHistoryTracker'
import { getGymsRawPath } from '../utils/pathUtils'
import { 
  CrawlingConfig, 
  CrawlingResult, 
  CrawlingOptions, 
  ProcessedGymData,
  CrawlingStatus 
} from '@backend/modules/crawling/types/CrawlingTypes'

export class CrawlingService {
  private gymRepo: Repository<Gym>
  private dataProcessor: DataProcessor
  private publicApiSource: PublicApiSource
  private optimizedCrawlingSource: OptimizedGymCrawlingSource
  private dataMerger: DataMerger
  private enhancedDataMerger: EnhancedDataMerger
  private dataValidator: DataValidator
  private historyTracker: CrawlingHistoryTracker
  private config: CrawlingConfig
  private status: CrawlingStatus

  constructor(gymRepo: Repository<Gym>) {
    this.gymRepo = gymRepo
    this.dataProcessor = new DataProcessor(gymRepo)
    this.publicApiSource = new PublicApiSource()
    this.optimizedCrawlingSource = new OptimizedGymCrawlingSource()
    this.dataMerger = new DataMerger()
    this.enhancedDataMerger = new EnhancedDataMerger()
    this.dataValidator = new DataValidator()
    this.historyTracker = new CrawlingHistoryTracker()
    
    this.config = {
      enablePublicApi: true,
      enableCrawling: true, // ì›¹ í¬ë¡¤ë§ í™œì„±í™”
      enableDataMerging: true,
      enableQualityCheck: true,
      batchSize: 5, // ì›¹ í¬ë¡¤ë§ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ëŒ€í­ ê°ì†Œ
      maxConcurrentRequests: 1, // ë™ì‹œ ìš”ì²­ ìˆ˜ 1ê°œë¡œ ì œí•œ
      delayBetweenBatches: 10000, // ì§€ì—° ì‹œê°„ ëŒ€í­ ì¦ê°€ (10ì´ˆ)
      maxRetries: 3,
      timeout: 30000,
      saveToFile: true,
      saveToDatabase: true
    }

    this.status = {
      isRunning: false,
      currentStep: '',
      progress: { current: 0, total: 0, percentage: 0 },
      startTime: null,
      estimatedCompletion: null,
      errors: []
    }
  }

  /**
   * í¬ë¡¤ë§ ì„¤ì • ì—…ë°ì´íŠ¸
   */
  updateConfig(newConfig: Partial<CrawlingConfig>): void {
    this.config = { ...this.config, ...newConfig }
  }

  /**
   * í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ
   */
  getStatus(): CrawlingStatus {
    return { ...this.status }
  }

  /**
   * ê³µê³µ APIë¥¼ í†µí•œ í—¬ìŠ¤ì¥ ë°ì´í„° ìˆ˜ì§‘
   */
  async collectFromPublicAPI(): Promise<ProcessedGymData[]> {
    console.log('ğŸ“¡ ê³µê³µ APIì—ì„œ í—¬ìŠ¤ì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘')
    
    try {
      // ê³µê³µ API ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
      const publicApiData = await this.publicApiSource.fetchAllPublicAPIData()
      
      // ë°ì´í„° ë³‘í•© ë° ì •ì œ
      const mergedData = this.dataMerger.mergeGymData(publicApiData)
      
      console.log(`âœ… ê³µê³µ API ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: ${mergedData.length}ê°œ í—¬ìŠ¤ì¥`)
      return mergedData
      
    } catch (error) {
      console.error('âŒ ê³µê³µ API ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨:', error)
      return []
    }
  }

  /**
   * íŠ¹ì • í—¬ìŠ¤ì¥ ì •ë³´ í¬ë¡¤ë§ (ì›¹ í¬ë¡¤ë§)
   */
  async crawlGymDetails(options: CrawlingOptions): Promise<ProcessedGymData | null> {
    if (!this.config.enableCrawling) {
      console.log('âš ï¸ í¬ë¡¤ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤')
      return null
    }

    if (!options.gymName) {
      console.log('âŒ í—¬ìŠ¤ì¥ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤')
      return null
    }

    console.log(`ğŸ” í—¬ìŠ¤ì¥ ì •ë³´ í¬ë¡¤ë§ ì‹œì‘: ${options.gymName}`)
    
    try {
      // ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ í—¬ìŠ¤ì¥ ì •ë³´ ìˆ˜ì§‘
      // ì›¹ í¬ë¡¤ë§ì€ OptimizedGymCrawlingSourceë¥¼ í†µí•´ ì²˜ë¦¬
      const webResult = await this.optimizedCrawlingSource.crawlGymsFromRawData([{
        name: options.gymName || '',
        address: options.gymAddress || '',
        source: 'manual_search',
        confidence: 0.5
      }])
      
      if (!webResult) {
        console.log(`âŒ í—¬ìŠ¤ì¥ í¬ë¡¤ë§ ì‹¤íŒ¨: ${options.gymName}`)
        return null
      }
      
      console.log(`âœ… í—¬ìŠ¤ì¥ í¬ë¡¤ë§ ì™„ë£Œ: ${options.gymName}`)
      return webResult[0] || null
      
    } catch (error) {
      console.error(`âŒ í—¬ìŠ¤ì¥ í¬ë¡¤ë§ ì˜¤ë¥˜: ${options.gymName}`, error)
      return null
    }
  }

  /**
   * í†µí•© í¬ë¡¤ë§ ì‹¤í–‰ (ìƒˆë¡œìš´ êµ¬ì¡°)
   */
  async executeIntegratedCrawling(): Promise<CrawlingResult> {
    if (this.status.isRunning) {
      throw new Error('í¬ë¡¤ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤')
    }

    this.status.isRunning = true
    this.status.startTime = new Date()
    this.status.errors = []
    this.status.currentStep = 'ì´ˆê¸°í™”'

    // íˆìŠ¤í† ë¦¬ ì¶”ì  ì‹œì‘
    const sessionId = this.historyTracker.startSession(this.config)

    console.log('ğŸš€ í†µí•© í¬ë¡¤ë§ ì‹œì‘ (ìƒˆë¡œìš´ êµ¬ì¡°)')

    const result: CrawlingResult = {
      success: false,
      totalGyms: 0,
      publicApiGyms: 0,
      crawlingGyms: 0,
      mergedGyms: 0,
      duration: 0,
      processingTime: 0,
      errors: [],
      warnings: [],
      dataQuality: {
        average: 0,
        min: 0,
        max: 0,
        distribution: {},
        complete: 0,
        partial: 0,
        minimal: 0,
        averageQualityScore: 0
      }
    }

    try {
      // 1. ê³µê³µ APIì—ì„œ ì˜ì—…ì¤‘ì¸ í—¬ìŠ¤ì¥ ë°ì´í„° ìˆ˜ì§‘ (gym/gx/pt/í¬ë¡œìŠ¤í•ë§Œ)
      if (this.config.enablePublicApi) {
        this.status.currentStep = 'ê³µê³µ API ë°ì´í„° ìˆ˜ì§‘ (ì˜ì—…ì¤‘ + í—¬ìŠ¤ì¥ í•„í„°ë§)'
        const publicApiData = await this.collectFromPublicAPI()
        result.publicApiGyms = publicApiData.length
        
        // íˆìŠ¤í† ë¦¬ ê¸°ë¡
        this.historyTracker.recordApiCollection(
          { current: publicApiData.length, total: publicApiData.length },
          { count: publicApiData.length }
        )
        
        console.log(`âœ… ê³µê³µ API ìˆ˜ì§‘ ì™„ë£Œ: ${publicApiData.length}ê°œ í—¬ìŠ¤ì¥ (ì˜ì—…ì¤‘ + í•„í„°ë§ë¨)`)
        
        // ê³µê³µ API ë°ì´í„°ë¥¼ gyms_raw.jsonì— ì €ì¥
        if (this.config.saveToFile) {
          await this.saveToGymsRaw(publicApiData)
        }
      }

      // 2. gyms_raw.jsonì˜ nameìœ¼ë¡œ ì›¹ í¬ë¡¤ë§
      if (this.config.enableCrawling) {
        this.status.currentStep = 'gyms_raw name ê¸°ë°˜ ì›¹ í¬ë¡¤ë§'
        const crawlingResults = await this.crawlGymsFromRawData()
        result.crawlingGyms = crawlingResults.length
        
        // íˆìŠ¤í† ë¦¬ ê¸°ë¡
        const crawlingProgress = this.getStatus()
        this.historyTracker.recordNameCrawling(crawlingProgress)
        
        console.log(`âœ… name ê¸°ë°˜ í¬ë¡¤ë§ ì™„ë£Œ: ${crawlingResults.length}ê°œ í—¬ìŠ¤ì¥`)
        
        // í¬ë¡¤ë§ ê²°ê³¼ë¥¼ gyms_raw.jsonì— ë³‘í•©
        if (this.config.saveToFile && crawlingResults.length > 0) {
          await this.mergeAndSaveToGymsRaw(crawlingResults)
        }
      }

      // 3. ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
      if (this.config.enableQualityCheck) {
        this.status.currentStep = 'ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬'
        const qualityResult = await this.dataProcessor.checkDataQuality()
        result.dataQuality = qualityResult
      }

      // 4. ìµœì¢… ê²°ê³¼ ê³„ì‚°
      result.totalGyms = result.publicApiGyms + result.crawlingGyms
      result.success = true
      result.duration = Date.now() - this.status.startTime.getTime()

      console.log(`âœ… í†µí•© í¬ë¡¤ë§ ì™„ë£Œ: ê³µê³µAPI ${result.publicApiGyms}ê°œ, name í¬ë¡¤ë§ ${result.crawlingGyms}ê°œ, ì´ ${result.totalGyms}ê°œ í—¬ìŠ¤ì¥, ${(result.duration / 1000).toFixed(1)}ì´ˆ`)

    } catch (error) {
      result.success = false
      const errorMessage = error instanceof Error ? error.message : String(error)
      result.errors.push(errorMessage)
      this.status.errors.push(errorMessage)
      
      // íˆìŠ¤í† ë¦¬ì— ì˜¤ë¥˜ ê¸°ë¡
      this.historyTracker.recordError(errorMessage, this.status.currentStep)
      
      console.error('âŒ í†µí•© í¬ë¡¤ë§ ì‹¤íŒ¨:', error)
    } finally {
      this.status.isRunning = false
      this.status.currentStep = 'ì™„ë£Œ'
      
      // ì„¸ì…˜ ì¢…ë£Œ
      this.historyTracker.endSession(sessionId, result.success ? 'completed' : 'failed')
      
      // íˆìŠ¤í† ë¦¬ ì €ì¥
      await this.historyTracker.saveHistoryToFile()
    }

    return result
  }

  /**
   * gyms_raw.jsonì˜ nameìœ¼ë¡œ ì›¹ í¬ë¡¤ë§
   */
  private async crawlGymsFromRawData(): Promise<ProcessedGymData[]> {
    console.log('ğŸ” gyms_raw.json ê¸°ë°˜ ì›¹ í¬ë¡¤ë§ ì‹œì‘')
    
    try {
      // gyms_raw.json íŒŒì¼ ì½ê¸°
      const fs = await import('fs/promises')
      const filePath = getGymsRawPath()
      
      let gymsRawData: any[] = []
      try {
        const content = await fs.readFile(filePath, 'utf-8')
        gymsRawData = JSON.parse(content)
        console.log(`ğŸ“„ gyms_raw.json ë¡œë“œ ì™„ë£Œ: ${gymsRawData.length}ê°œ í—¬ìŠ¤ì¥`)
      } catch (error) {
        console.error('âŒ gyms_raw.json íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:', error)
        return []
      }

      if (gymsRawData.length === 0) {
        console.log('âš ï¸ gyms_raw.jsonì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤')
        return []
      }

      // í—¬ìŠ¤ì¥ ì´ë¦„ìœ¼ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
      const enhancedResults = await this.optimizedCrawlingSource.crawlGymsFromRawData(gymsRawData)
      
      // EnhancedGymInfoë¥¼ ProcessedGymDataë¡œ ë³€í™˜
      const crawlingResults: ProcessedGymData[] = enhancedResults.map((enhancedInfo, index) => {
        const originalGym = gymsRawData[index]
        return this.enhancedDataMerger.convertEnhancedGymInfoToProcessedGymData(enhancedInfo, originalGym)
      })
      
      console.log(`âœ… gyms_raw ê¸°ë°˜ í¬ë¡¤ë§ ì™„ë£Œ: ${crawlingResults.length}ê°œ í—¬ìŠ¤ì¥`)
      return crawlingResults
      
    } catch (error) {
      console.error('âŒ gyms_raw ê¸°ë°˜ í¬ë¡¤ë§ ì‹¤íŒ¨:', error)
      return []
    }
  }

  /**
   * í¬ë¡¤ë§ ê²°ê³¼ë¥¼ gyms_raw.jsonì— ë³‘í•©í•˜ì—¬ ì €ì¥
   */
  async mergeAndSaveToGymsRaw(crawledData: ProcessedGymData[]): Promise<{successfulMerges: number, fallbackUsed: number, qualityScore: number}> {
    try {
      const fs = await import('fs/promises')
      const filePath = getGymsRawPath()
      
      // ê¸°ì¡´ ë°ì´í„° ì½ê¸°
      let existingData: any[] = []
      try {
        const existingContent = await fs.readFile(filePath, 'utf-8')
        existingData = JSON.parse(existingContent)
      } catch (error) {
        console.log('ğŸ“„ gyms_raw.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
        return { successfulMerges: 0, fallbackUsed: 0, qualityScore: 0 }
      }

      // í–¥ìƒëœ ë°ì´í„° ë³‘í•© ì‹¤í–‰
      const mergeResult = await this.enhancedDataMerger.mergeGymDataWithCrawling(existingData, crawledData)
      
      // ë³‘í•©ëœ ë°ì´í„° ì €ì¥
      await fs.writeFile(filePath, JSON.stringify(mergeResult.mergedData, null, 2), 'utf-8')
      
      console.log(`ğŸ’¾ gyms_raw.json ë³‘í•© ì €ì¥ ì™„ë£Œ: ${mergeResult.mergedData.length}ê°œ í—¬ìŠ¤ì¥`)
      console.log(`ğŸ“Š ë³‘í•© í†µê³„: ì„±ê³µ ${mergeResult.statistics.successfullyMerged}ê°œ, í´ë°± ${mergeResult.statistics.fallbackUsed}ê°œ, ì¤‘ë³µì œê±° ${mergeResult.statistics.duplicatesRemoved}ê°œ`)
      console.log(`â­ í’ˆì§ˆ ì ìˆ˜: ${mergeResult.statistics.qualityScore.toFixed(2)}`)
      
      if (mergeResult.conflicts.length > 0) {
        console.log(`âš ï¸ ì¶©ëŒ ë°œìƒ: ${mergeResult.conflicts.length}ê°œ í•„ë“œ`)
        mergeResult.conflicts.forEach(conflict => {
          console.log(`  - ${conflict.gymName}: ${conflict.field} (${conflict.resolution})`)
        })
      }
      
      return {
        successfulMerges: mergeResult.statistics.successfullyMerged,
        fallbackUsed: mergeResult.statistics.fallbackUsed,
        qualityScore: mergeResult.statistics.qualityScore
      }
      
    } catch (error) {
      console.error('âŒ gyms_raw.json ë³‘í•© ì €ì¥ ì‹¤íŒ¨:', error)
      return { successfulMerges: 0, fallbackUsed: 0, qualityScore: 0 }
    }
  }

  /**
   * í¬ë¡¤ë§ ì§„í–‰ìƒí™© ì¡°íšŒ
   */
  getCrawlingProgress() {
    return this.status
  }

  /**
   * í˜„ì¬ ì„¸ì…˜ ì¡°íšŒ
   */
  getCurrentSession() {
    return this.historyTracker.getCurrentSession()
  }

  /**
   * ì„¸ì…˜ ì¡°íšŒ
   */
  getSession(sessionId: string) {
    return this.historyTracker.getSession(sessionId)
  }

  /**
   * ìµœê·¼ ì„¸ì…˜ ì¡°íšŒ
   */
  getRecentSessions(limit: number = 10) {
    return this.historyTracker.getRecentSessions(limit)
  }

  /**
   * ì„¸ì…˜ í†µê³„ ì¡°íšŒ
   */
  getSessionStatistics() {
    return this.historyTracker.getSessionStatistics()
  }

  /**
   * íˆìŠ¤í† ë¦¬ ë¡œë“œ
   */
  async loadHistory() {
    await this.historyTracker.loadHistoryFromFile()
  }

  /**
   * ê³µê³µ API ë°ì´í„°ë¡œ ì›¹ í¬ë¡¤ë§í•˜ì—¬ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ (ë ˆê±°ì‹œ)
   */
  private async crawlAdditionalInfo(): Promise<ProcessedGymData[]> {
    console.log('ğŸ” ê³µê³µ API ë°ì´í„°ë¡œ ì›¹ í¬ë¡¤ë§ ì‹œì‘')
    
    try {
      // ê³µê³µ APIì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
      const publicApiData = await this.collectFromPublicAPI()
      const crawlingResults: ProcessedGymData[] = []
      
      // ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
      for (let i = 0; i < publicApiData.length; i += this.config.batchSize) {
        const batch = publicApiData.slice(i, i + this.config.batchSize)
        
        console.log(`ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: ${i + 1}-${Math.min(i + this.config.batchSize, publicApiData.length)}/${publicApiData.length}`)
        
        // ë°°ì¹˜ ë‚´ì—ì„œ ìˆœì°¨ ì²˜ë¦¬ (Rate limiting ë°©ì§€)
        const batchResults: PromiseSettledResult<ProcessedGymData>[] = []
        
        for (const gym of batch) {
          try {
            const crawlingResults = await this.optimizedCrawlingSource.crawlGymsFromRawData([gym])
            const crawlingResult = crawlingResults[0] || null
            if (crawlingResult) {
              // ê³µê³µ API ë°ì´í„°ì™€ í¬ë¡¤ë§ ë°ì´í„° ë³‘í•©
              const mergedResult = this.dataMerger.mergeGymData([gym, crawlingResult])[0]
              batchResults.push({ status: 'fulfilled', value: mergedResult })
            } else {
              batchResults.push({ status: 'fulfilled', value: gym })
            }
          } catch (error) {
            console.error(`âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: ${gym.name}`, error)
            batchResults.push({ status: 'fulfilled', value: gym })
          }
          
          // ê° í—¬ìŠ¤ì¥ ì²˜ë¦¬ í›„ ì§€ì—°
          await new Promise(resolve => setTimeout(resolve, 2000))
        }
        const validResults = batchResults
          .filter(result => result.status === 'fulfilled')
          .map(result => (result as PromiseFulfilledResult<ProcessedGymData>).value)
        
        crawlingResults.push(...validResults)
        
        // ë°°ì¹˜ ê°„ ì§€ì—°
        if (i + this.config.batchSize < publicApiData.length) {
          await new Promise(resolve => setTimeout(resolve, this.config.delayBetweenBatches))
        }
      }
      
      console.log(`âœ… ì›¹ í¬ë¡¤ë§ ì™„ë£Œ: ${crawlingResults.length}ê°œ í—¬ìŠ¤ì¥ ì²˜ë¦¬`)
      return crawlingResults
      
    } catch (error) {
      console.error('âŒ ì›¹ í¬ë¡¤ë§ ì‹¤íŒ¨:', error)
      return []
    }
  }

  /**
   * gyms_raw.json íŒŒì¼ì— ë°ì´í„° ì €ì¥
   */
  private async saveToGymsRaw(data: ProcessedGymData[]): Promise<void> {
    try {
      const fs = await import('fs/promises')
      const filePath = getGymsRawPath()
      
      // ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
      let existingData: ProcessedGymData[] = []
      try {
        const existingContent = await fs.readFile(filePath, 'utf-8')
        existingData = JSON.parse(existingContent)
      } catch (error) {
        // íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨ ì‹œ ë¹ˆ ë°°ì—´ë¡œ ì‹œì‘
        console.log('ğŸ“„ ìƒˆë¡œìš´ gyms_raw.json íŒŒì¼ ìƒì„±')
      }
      
      // ì¤‘ë³µ ì œê±° (ì´ë¦„ê³¼ ì£¼ì†Œë¡œ ë¹„êµ)
      const mergedData = this.dataMerger.mergeGymData([...existingData, ...data])
      
      await fs.writeFile(filePath, JSON.stringify(mergedData, null, 2), 'utf-8')
      console.log(`ğŸ’¾ gyms_raw.json ì €ì¥ ì™„ë£Œ: ${mergedData.length}ê°œ í—¬ìŠ¤ì¥`)
      
    } catch (error) {
      console.error('âŒ gyms_raw.json ì €ì¥ ì‹¤íŒ¨:', error)
    }
  }

  /**
   * gyms_raw.json íŒŒì¼ì— ë°ì´í„° ì¶”ê°€
   */
  private async appendToGymsRaw(data: ProcessedGymData[]): Promise<void> {
    try {
      const fs = await import('fs/promises')
      const filePath = getGymsRawPath()
      
      // ê¸°ì¡´ ë°ì´í„° ì½ê¸°
      let existingData: ProcessedGymData[] = []
      try {
        const existingContent = await fs.readFile(filePath, 'utf-8')
        existingData = JSON.parse(existingContent)
      } catch (error) {
        console.log('ğŸ“„ gyms_raw.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
        return
      }
      
      // ì¤‘ë³µ ì œê±° í›„ ì¶”ê°€
      const mergedData = this.dataMerger.mergeGymData([...existingData, ...data])
      
      await fs.writeFile(filePath, JSON.stringify(mergedData, null, 2), 'utf-8')
      console.log(`ğŸ’¾ gyms_raw.json ì—…ë°ì´íŠ¸ ì™„ë£Œ: ${mergedData.length}ê°œ í—¬ìŠ¤ì¥`)
      
    } catch (error) {
      console.error('âŒ gyms_raw.json ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', error)
    }
  }

  /**
   * í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì •ë¦¬
   */
  async cleanup(): Promise<void> {
    console.log('ğŸ§¹ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì •ë¦¬ ì¤‘...')
    
    // ì‹¤í–‰ ì¤‘ì¸ í¬ë¡¤ë§ì´ ìˆë‹¤ë©´ ì¤‘ë‹¨
    if (this.status.isRunning) {
      this.status.isRunning = false
      this.status.currentStep = 'ì¤‘ë‹¨ë¨'
    }
    
    // ë°ì´í„° í”„ë¡œì„¸ì„œ ì •ë¦¬
    await this.dataProcessor.cleanup()
    
    console.log('âœ… í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ')
  }
}
