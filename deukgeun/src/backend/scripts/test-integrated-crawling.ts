/**
 * í†µí•© í¬ë¡¤ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
 * 
 * í…ŒìŠ¤íŠ¸ ìˆœì„œ:
 * 1. ì„œìš¸ APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘
 * 2. gyms_raw.jsonì— ì €ì¥
 * 3. name ê¸°ë°˜ ì›¹ í¬ë¡¤ë§
 * 4. ë°ì´í„° ë³‘í•© ë° gyms_raw.json ì—…ë°ì´íŠ¸
 */

import 'reflect-metadata'
import { DataSource } from 'typeorm'
import { CrawlingService } from '../modules/crawling/core/CrawlingService.js'
import { Gym } from '../entities/Gym.js'
import * as dotenv from 'dotenv'
import * as path from 'path'
import { getDirname } from '../utils/pathUtils'

const __dirname = getDirname()

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.config({ path: path.join(__dirname, '..', '.env') })
dotenv.config({ path: path.join(__dirname, '..', 'env.development') })

// í…ŒìŠ¤íŠ¸ìš© í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
if (!process.env.SEOUL_OPENAPI_KEY) {
  process.env.SEOUL_OPENAPI_KEY = '467572475373737933314e4e494377'
}

async function testIntegratedCrawling() {
  console.log('ğŸ§ª í†µí•© í¬ë¡¤ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘')
  console.log('=' .repeat(70))
  
  // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • (ì˜µì…˜, ì—†ì–´ë„ íŒŒì¼ ê¸°ë°˜ ì‘ì—…ì€ ê°€ëŠ¥)
  let dataSource: DataSource | null = null
  let gymRepository: any = null
  
  try {
    // ê°„ë‹¨í•œ mock repository ìƒì„± (DB ì—†ì´ í…ŒìŠ¤íŠ¸)
    const mockRepository = {
      find: async () => [],
      findOne: async () => null,
      save: async (data: any) => data,
      create: (data: any) => data
    } as any
    
    gymRepository = mockRepository
    
    console.log('âœ… Mock Repository ì´ˆê¸°í™” ì™„ë£Œ')
    
  } catch (error) {
    console.log('âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤ (íŒŒì¼ ê¸°ë°˜ í…ŒìŠ¤íŠ¸)')
    gymRepository = {} as any
  }
  
  try {
    // í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    const crawlingService = new CrawlingService(gymRepository)
    
    // í¬ë¡¤ë§ ì„¤ì • (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹ ë¥´ê²Œ ì„¤ì •)
    crawlingService.updateConfig({
      enablePublicApi: true,
      enableCrawling: true, // ì›¹ í¬ë¡¤ë§ í™œì„±í™”
      enableDataMerging: true,
      enableQualityCheck: true,
      batchSize: 3, // í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì‘ì€ ë°°ì¹˜ í¬ê¸°
      maxConcurrentRequests: 1,
      delayBetweenBatches: 2000, // 2ì´ˆ ì§€ì—°
      maxRetries: 2,
      timeout: 15000,
      saveToFile: true,
      saveToDatabase: false // DB ì—†ì´ íŒŒì¼ë§Œ ì‚¬ìš©
    })
    
    console.log('\nğŸ“‹ í¬ë¡¤ë§ ì„¤ì •:')
    console.log('- ê³µê³µ API ìˆ˜ì§‘: í™œì„±í™”')
    console.log('- ì›¹ í¬ë¡¤ë§: í™œì„±í™”')
    console.log('- ë°°ì¹˜ í¬ê¸°: 3ê°œ')
    console.log('- ì§€ì—° ì‹œê°„: 2ì´ˆ')
    console.log('')
    
    // í†µí•© í¬ë¡¤ë§ ì‹¤í–‰
    console.log('ğŸš€ í†µí•© í¬ë¡¤ë§ ì‹¤í–‰ ì‹œì‘...\n')
    const result = await crawlingService.executeIntegratedCrawling()
    
    // ê²°ê³¼ ì¶œë ¥
    console.log('\n' + '=' .repeat(70))
    console.log('ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½')
    console.log('=' .repeat(70))
    console.log(`âœ… ì„±ê³µ ì—¬ë¶€: ${result.success ? 'ì„±ê³µ' : 'ì‹¤íŒ¨'}`)
    console.log(`ğŸ“¡ ê³µê³µ API ìˆ˜ì§‘: ${result.publicApiGyms}ê°œ í—¬ìŠ¤ì¥`)
    console.log(`ğŸ” name ê¸°ë°˜ í¬ë¡¤ë§: ${result.crawlingGyms}ê°œ í—¬ìŠ¤ì¥`)
    console.log(`ğŸ“¦ ì´ ì²˜ë¦¬ëœ í—¬ìŠ¤ì¥: ${result.totalGyms}ê°œ`)
    console.log(`â±ï¸  ì†Œìš” ì‹œê°„: ${(result.duration / 1000).toFixed(1)}ì´ˆ`)
    
    if (result.dataQuality) {
      console.log('\nğŸ“ˆ ë°ì´í„° í’ˆì§ˆ:')
      console.log(`- ì™„ì „í•œ ë°ì´í„°: ${result.dataQuality.complete || 0}ê°œ`)
      console.log(`- ë¶€ë¶„ ë°ì´í„°: ${result.dataQuality.partial || 0}ê°œ`)
      console.log(`- ìµœì†Œ ë°ì´í„°: ${result.dataQuality.minimal || 0}ê°œ`)
      console.log(`- í‰ê·  í’ˆì§ˆ ì ìˆ˜: ${result.dataQuality.averageQualityScore?.toFixed(2) || 'N/A'}`)
    }
    
    if (result.errors && result.errors.length > 0) {
      console.log('\nâš ï¸ ì˜¤ë¥˜:')
      result.errors.forEach((error, index) => {
        console.log(`${index + 1}. ${error}`)
      })
    }
    
    // ì„¸ì…˜ í†µê³„
    const sessionStats = crawlingService.getSessionStatistics()
    console.log('\nğŸ“Š ì„¸ì…˜ í†µê³„:')
    console.log(`- ì´ ì„¸ì…˜ ìˆ˜: ${sessionStats.totalSessions}`)
    console.log(`- ì™„ë£Œëœ ì„¸ì…˜: ${sessionStats.completedSessions}`)
    console.log(`- ì‹¤íŒ¨í•œ ì„¸ì…˜: ${sessionStats.failedSessions}`)
    console.log(`- ì´ ì²˜ë¦¬ í—¬ìŠ¤ì¥: ${sessionStats.totalGymsProcessed}`)
    
    console.log('\nâœ… í†µí•© í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
    console.log('\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:')
    console.log('1. src/data/gyms_raw.json íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”')
    console.log('2. logs/crawling-history.jsonì—ì„œ íˆìŠ¤í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”')
    
  } catch (error) {
    console.error('\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error)
    if (error instanceof Error) {
      console.error('ì˜¤ë¥˜ ë©”ì‹œì§€:', error.message)
      console.error('ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:', error.stack)
    }
  } finally {
    // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
    if (dataSource && (dataSource as DataSource).isInitialized) {
      await (dataSource as DataSource).destroy()
      console.log('\nâœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ')
    }
  }
  
  console.log('\n' + '=' .repeat(70))
  console.log('ğŸ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ')
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
testIntegratedCrawling()
  .then(() => process.exit(0))
  .catch((error) => {
    console.error('ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨:', error)
    process.exit(1)
  })

export { testIntegratedCrawling }

